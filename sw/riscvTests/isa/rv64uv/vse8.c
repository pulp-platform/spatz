#include "vector_macros.h"


void TEST_CASE1(void) {
  VSET(16, e8, m1);
  VLOAD_8(v0, 0x11, 0x22);
  volatile uint8_t ALIGNED_I8[1024];
  VLOAD_8(v1, 0x01, 0x23, 0x45, 0x67, 0x89, 0xab, 0xcd, 0xef, 0x11, 0x22, 0x33,
          0x44, 0x55, 0x66, 0x77, 0x88);
  asm volatile("vse8.v v1, (%0)" ::"r"(ALIGNED_I8));
  VVCMP_U8(1, ALIGNED_I8, 0x01, 0x23, 0x45, 0x67, 0x89, 0xab, 0xcd, 0xef, 0x11, 0x22, 0x33,
          0x44, 0x55, 0x66, 0x77, 0x88);
}

void TEST_CASE2(void) {
  VSET(16, e8, m1);
  volatile uint8_t ALIGNED_I8[16]={0};
  VLOAD_8(v6, 0xe0, 0xd3, 0x40, 0xd1, 0x84, 0x48, 0x89, 0x88, 0x88, 0xae, 0x08,
          0x91, 0x02, 0x59, 0x11, 0x89);
  asm volatile("vse8.v v6, (%0)" ::"r"(ALIGNED_I8));
  VCLEAR(v6);
  VVCMP_U8(2, ALIGNED_I8, 0xe0, 0xd3, 0x40, 0xd1, 0x84, 0x48, 0x89, 0x88, 0x88,
           0xae, 0x08, 0x91, 0x02, 0x59, 0x11, 0x89);
}

//*******Checking functionality of vse8 with different values of masking
// register******//
void TEST_CASE3(void) {
  VSET(16, e8, m1);
  volatile uint8_t ALIGNED_I8[16];
  VLOAD_8(v0, 0xFF, 0xFF);
  VLOAD_8(v3, 0xe0, 0xd3, 0x40, 0xd1, 0x84, 0x48, 0x89, 0x88, 0x88, 0xae, 0x08,
          0x91, 0x02, 0x59, 0x11, 0x89);
//   VLOAD_8(v0, 0xFF, 0xFF);
  asm volatile("vse8.v v3, (%0), v0.t" ::"r"(ALIGNED_I8));
  VCLEAR(v3);
  VVCMP_U8(3, ALIGNED_I8, 0xe0, 0xd3, 0x40, 0xd1, 0x84, 0x48, 0x89, 0x88, 0x88,
           0xae, 0x08, 0x91, 0x02, 0x59, 0x11, 0x89);
}

void TEST_CASE4(void) {
  VSET(16, e8, m1);
  volatile uint8_t ALIGNED_I8[16];
  VLOAD_8(v3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16);
  asm volatile("vse8.v v3, (%0)" ::"r"(ALIGNED_I8));
  VCLEAR(v3);
  VLOAD_8(v3, 0xe0, 0xd3, 0x40, 0xd1, 0x84, 0x48, 0x89, 0x88, 0x88, 0xae, 0x08,
          0x91, 0x02, 0x59, 0x11, 0x89);
  VLOAD_8(v0, 0x00, 0x00);
  asm volatile("vse8.v v3, (%0), v0.t" ::"r"(ALIGNED_I8));
  VCLEAR(v3);
  VVCMP_U8(4, ALIGNED_I8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,
           16);
}

void TEST_CASE5(void) {
  VSET(16, e8, m1);
  volatile uint8_t ALIGNED_I8[16];
  VLOAD_8(v3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16);
  asm volatile("vse8.v v3, (%0)" ::"r"(ALIGNED_I8));
  VCLEAR(v3);
  VLOAD_8(v3, 0xe0, 0xd3, 0x40, 0xd1, 0x84, 0x48, 0x89, 0x88, 0x88, 0xae, 0x08,
          0x91, 0x02, 0x59, 0x11, 0x89);
  VLOAD_8(v0, 0xAA, 0xAA);
  asm volatile("vse8.v v3, (%0), v0.t" ::"r"(ALIGNED_I8));
  VCLEAR(v3);
  VVCMP_U8(5, ALIGNED_I8, 1, 0xd3, 3, 0xd1, 5, 0x48, 7, 0x88, 9, 0xae, 11, 0x91,
           13, 0x59, 15, 0x89);
}

int main(void) {
  INIT_CHECK();
  enable_vec();

//   TEST_CASE0();
  TEST_CASE1();
  TEST_CASE2();
  TEST_CASE3();
  TEST_CASE4();
  TEST_CASE5();

  EXIT_CHECK();
}